{"name":"Camkart","tagline":"Online Camera Recommender System using Nutch, Solr and Django","body":"# Camkart\r\nA Camera Search Engine build on the Django Framework with Solr in the backend.\r\n\r\n###1. Objectives\r\n\r\nOur objective for this project was to build a search system for Nikon Camera which not only provides highly relevant content in response to user’s natural language queries but also provide a ranked list of retrieved products on the basis of the sentiment score of the product reviews (obtained from Flipkart), price and various other features. The search engine should produce various search filters for price, sentiment etc. and provide a simple user friendly interface.\r\n\r\n###2. Approach\r\n\r\nWe crawled the data from Flipkart.com using Nutch and BeautifulSoup and decided upon a set of metadata which might be used in the indexing.\r\nWe then populated the metadata and created the database of all the products and fed it to solr for Indexing. \r\nSentiment Analysis was performed on the reviews for each product and user friendly interface for queries was implemented using Django Framework.\r\n\r\n###3. Query Processing Algorithm\r\n\r\nThe query is passed to solr index which fetches an initial list of ranked documents based on the Solr scoring model which consists of tf (term freq.), idf (inv. doc. freq.), coord (Coordination Factor), fieldNorm (Field length) parameters . This list is filtered using  a boolean model on the input range filter values . This filtered list of documents is then sorted on the sentiment score of the documents ( each documents corresponds to one camera ) based on the reviews obtained by the product to obtain the final ranked list of documents ( products ) .\r\n\r\n###4. Crawling\r\n\r\nObtained list of product URLs from Flipkart.com using BeautifulSoup\r\nFed list of URLs as seed to Nutch\r\nCrawled each product page till depth 1 and obtained product data , other relevant data was obtained using beautifulSoup\r\n\r\n###5. Metadata\r\n\r\nWe chose the following metadata for indexing:<br>\r\nLink of the product on flipkart<br>\r\nColor of product<br>\r\nImage url<br>\r\nPrice<br>\r\nMegapixels<br>\r\nName of the product<br>\r\nNumber of people who have reviewed the product<br>\r\nNumber of people who have rated the product<br>\r\nAverage rating of the product<br>\r\n10 reviews<br>\r\nType of Camera (DSLR etc)<br>\r\nType of sensor used<br>\r\nAverage Sentiment score of the reviews.<br>\r\n\r\nPopulating the metadata: We used Python library BeautifulSoup to crawl the urls. We then parsed the webpages to get the relevant selected metadata from the respective tags of crawled xml files and fed the populated metadata into django database.\r\n\r\n###6. Indexing ( Documents Indexed : 436 )\r\n\r\nWe built an inverted index with the help of Solr. Solr inverts a page-centric data structure (page->words) to a keyword-centric data structure (word->pages).Then the index is stored by Solr in in a directory called index in the data directory.\r\n\r\nThen,we specified the schema in a file schema.xml.The following fields were used :<br>\r\nDocument text<br>\r\nProduct price<br>\r\nAverage rating of product<br>\r\nNumber of ratings<br>\r\nSentiment score<br>\r\n\r\nAfter data is added to Solr, it goes through analysis phase where it goes through a series of transformations Examples of transformations include lower-casing, removing word stems etc. The end result of the analysis are a series of tokens which are then added to the index, generated using NGramFilterFactory of Solr Library.\r\n\r\n###7. Solr scoring model\r\n\r\nThe score given to a document by Solr in response to a query is scored on the following parameters:<br>\r\ntf : term frequency of the token in a document . <br>\r\nidf : reciprocal of the frequency of the token in the corpus .<br>\r\ncoord : Coordination Factor . The more query terms that are found in the document , the higher its contribution to the score .<br>\r\nfieldNorm : Field length . The more words that a field contains , the lower it’s score . This factor penalizes document with longer field values . <br>\r\n\r\n###8. PreProcessing\r\n\r\nWe performed a number of preprocessing steps on the reviews before performing sentiment analysis. We followed the following text normalization procedure<br>\r\n\r\nTokenized the reviews and converted the text to lowercase.<br>\r\nRemove special characters. For eg, !@#%^&.<br>\r\nRemoved multiple occurrences of letters in a word.For eg, haaaapy -> haappy<br>\r\nPerformed spell correction on the word. For Eg, haapy - > happy<br>\r\nRemoved all the stop words in the tokenized text<br>\r\nPerformed Stemming to reduce the words to their base form. We used the Porter Stemmer for best results.<br>\r\n\r\n###9. Sentiment Analysis\r\nSentiment Polarity Classification of reviews done using Sentiwordnet\r\nSentiwordnet is a publicly lexical resource for opinion mining \r\nWordnet provides each Wordnet synset 's' three numerical scores Obj('s'), Pos('s') and Neg('s')\r\nThese scores describe the objectivity, positivity, and negativity of the terms contained in the synset\r\nEach review classified into positive, negative and neutral\r\nReview assigned sentiment score of +1, -1 and 0 respectively\r\nProduct assigned a sentiment score as the average of sentiment score of 10 product reviews\r\n\r\n###10. User Interface and its Features\r\n\r\nUser friendly and intuitive interface.\r\nFrontend designed using JQuery and Bootstrap framework\r\nDjango framework as backend integrated with Solr indexing, which was implemented using Haystack.\r\n\r\nNatural language queries are supported.\r\nFeatures to sort relevant results obtained on the basis of price or rating or sentiment score.\r\nFilters have been implemented for price, rating, number of ratings that a product obtained and sentiment score.\r\nSelection of a product redirects user to product page on Flipkart.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}